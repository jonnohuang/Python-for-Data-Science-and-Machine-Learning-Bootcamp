{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../DATA/fake_reg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>461.527929</td>\n",
       "      <td>999.787558</td>\n",
       "      <td>999.766096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>548.130011</td>\n",
       "      <td>998.861615</td>\n",
       "      <td>1001.042403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>410.297162</td>\n",
       "      <td>1000.070267</td>\n",
       "      <td>998.844015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>540.382220</td>\n",
       "      <td>999.952251</td>\n",
       "      <td>1000.440940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>546.024553</td>\n",
       "      <td>1000.446011</td>\n",
       "      <td>1000.338531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        price     feature1     feature2\n",
       "0  461.527929   999.787558   999.766096\n",
       "1  548.130011   998.861615  1001.042403\n",
       "2  410.297162  1000.070267   998.844015\n",
       "3  540.382220   999.952251  1000.440940\n",
       "4  546.024553  1000.446011  1000.338531"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 3 columns):\n",
      "price       1000 non-null float64\n",
      "feature1    1000 non-null float64\n",
      "feature2    1000 non-null float64\n",
      "dtypes: float64(3)\n",
      "memory usage: 23.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x244b86ae148>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x540 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train_test_split in module sklearn.model_selection._split:\n",
      "\n",
      "train_test_split(*arrays, **options)\n",
      "    Split arrays or matrices into random train and test subsets\n",
      "    \n",
      "    Quick utility that wraps input validation and\n",
      "    ``next(ShuffleSplit().split(X, y))`` and application to input data\n",
      "    into a single call for splitting (and optionally subsampling) data in a\n",
      "    oneliner.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    *arrays : sequence of indexables with same length / shape[0]\n",
      "        Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "        matrices or pandas dataframes.\n",
      "    \n",
      "    test_size : float, int or None, optional (default=None)\n",
      "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "        of the dataset to include in the test split. If int, represents the\n",
      "        absolute number of test samples. If None, the value is set to the\n",
      "        complement of the train size. If ``train_size`` is also None, it will\n",
      "        be set to 0.25.\n",
      "    \n",
      "    train_size : float, int, or None, (default=None)\n",
      "        If float, should be between 0.0 and 1.0 and represent the\n",
      "        proportion of the dataset to include in the train split. If\n",
      "        int, represents the absolute number of train samples. If None,\n",
      "        the value is automatically set to the complement of the test size.\n",
      "    \n",
      "    random_state : int, RandomState instance or None, optional (default=None)\n",
      "        If int, random_state is the seed used by the random number generator;\n",
      "        If RandomState instance, random_state is the random number generator;\n",
      "        If None, the random number generator is the RandomState instance used\n",
      "        by `np.random`.\n",
      "    \n",
      "    shuffle : boolean, optional (default=True)\n",
      "        Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "        then stratify must be None.\n",
      "    \n",
      "    stratify : array-like or None (default=None)\n",
      "        If not None, data is split in a stratified fashion, using this as\n",
      "        the class labels.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    splitting : list, length=2 * len(arrays)\n",
      "        List containing train-test split of inputs.\n",
      "    \n",
      "        .. versionadded:: 0.16\n",
      "            If the input is sparse, the output will be a\n",
      "            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "            input type.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.model_selection import train_test_split\n",
      "    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      "    >>> X\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5],\n",
      "           [6, 7],\n",
      "           [8, 9]])\n",
      "    >>> list(y)\n",
      "    [0, 1, 2, 3, 4]\n",
      "    \n",
      "    >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "    ...     X, y, test_size=0.33, random_state=42)\n",
      "    ...\n",
      "    >>> X_train\n",
      "    array([[4, 5],\n",
      "           [0, 1],\n",
      "           [6, 7]])\n",
      "    >>> y_train\n",
      "    [2, 0, 3]\n",
      "    >>> X_test\n",
      "    array([[2, 3],\n",
      "           [8, 9]])\n",
      "    >>> y_test\n",
      "    [1, 4]\n",
      "    \n",
      "    >>> train_test_split(y, shuffle=False)\n",
      "    [[0, 1, 2], [3, 4]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['feature1','feature2']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['price'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow 2.0 Keras Syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Sequential in module tensorflow.python.keras.engine.sequential:\n",
      "\n",
      "class Sequential(tensorflow.python.keras.engine.training.Model)\n",
      " |  Sequential(layers=None, name=None)\n",
      " |  \n",
      " |  Linear stack of layers.\n",
      " |  \n",
      " |  Arguments:\n",
      " |      layers: list of layers to add to the model.\n",
      " |  \n",
      " |  Example:\n",
      " |  \n",
      " |  ```python\n",
      " |  # Optionally, the first layer can receive an `input_shape` argument:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, input_shape=(500,)))\n",
      " |  # Afterwards, we do automatic shape inference:\n",
      " |  model.add(Dense(32))\n",
      " |  \n",
      " |  # This is identical to the following:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, input_dim=500))\n",
      " |  \n",
      " |  # And to the following:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, batch_input_shape=(None, 500)))\n",
      " |  \n",
      " |  # Note that you can also omit the `input_shape` argument:\n",
      " |  # In that case the model gets built the first time you call `fit` (or other\n",
      " |  # training and evaluation methods).\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32))\n",
      " |  model.add(Dense(32))\n",
      " |  model.compile(optimizer=optimizer, loss=loss)\n",
      " |  # This builds the model for the first time:\n",
      " |  model.fit(x, y, batch_size=32, epochs=10)\n",
      " |  \n",
      " |  # Note that when using this delayed-build pattern (no input shape specified),\n",
      " |  # the model doesn't have any weights until the first call\n",
      " |  # to a training/evaluation method (since it isn't yet built):\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32))\n",
      " |  model.add(Dense(32))\n",
      " |  model.weights  # returns []\n",
      " |  \n",
      " |  # Whereas if you specify the input shape, the model gets built continuously\n",
      " |  # as you are adding layers:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, input_shape=(500,)))\n",
      " |  model.add(Dense(32))\n",
      " |  model.weights  # returns list of length 4\n",
      " |  \n",
      " |  # When using the delayed-build pattern (no input shape specified), you can\n",
      " |  # choose to manually build your model by calling `build(batch_input_shape)`:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32))\n",
      " |  model.add(Dense(32))\n",
      " |  model.build((None, 500))\n",
      " |  model.weights  # returns list of length 4\n",
      " |  ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Sequential\n",
      " |      tensorflow.python.keras.engine.training.Model\n",
      " |      tensorflow.python.keras.engine.network.Network\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, layers=None, name=None)\n",
      " |  \n",
      " |  add(self, layer)\n",
      " |      Adds a layer instance on top of the layer stack.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          layer: layer instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          TypeError: If `layer` is not a layer instance.\n",
      " |          ValueError: In case the `layer` argument does not\n",
      " |              know its input shape.\n",
      " |          ValueError: In case the `layer` argument has\n",
      " |              multiple output tensors, or is already connected\n",
      " |              somewhere else (forbidden in `Sequential` models).\n",
      " |  \n",
      " |  build(self, input_shape=None)\n",
      " |      Builds the model based on input shapes received.\n",
      " |      \n",
      " |      This is to be used for subclassed models, which do not know at instantiation\n",
      " |      time what their inputs look like.\n",
      " |      \n",
      " |      This method only exists for users who want to call `model.build()` in a\n",
      " |      standalone way (as a substitute for calling the model on real data to\n",
      " |      build it). It will never be called by the framework (and thus it will\n",
      " |      never throw unexpected errors in an unrelated workflow).\n",
      " |      \n",
      " |      Args:\n",
      " |       input_shape: Single tuple, TensorShape, or list of shapes, where shapes\n",
      " |           are tuples, integers, or TensorShapes.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError:\n",
      " |          1. In case of invalid user-provided data (not of type tuple,\n",
      " |             list, or TensorShape).\n",
      " |          2. If the model requires call arguments that are agnostic\n",
      " |             to the input shapes (positional or kwarg in call signature).\n",
      " |          3. If not all layers were properly built.\n",
      " |          4. If float type inputs are not supported within the layers.\n",
      " |      \n",
      " |        In each of these cases, the user should build their model by calling it\n",
      " |        on real tensor data.\n",
      " |  \n",
      " |  call(self, inputs, training=None, mask=None)\n",
      " |      Calls the model on new inputs.\n",
      " |      \n",
      " |      In this case `call` just reapplies\n",
      " |      all ops in the graph to the new inputs\n",
      " |      (e.g. build a new computational graph from the provided inputs).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: A tensor or list of tensors.\n",
      " |          training: Boolean or boolean scalar tensor, indicating whether to run\n",
      " |            the `Network` in training mode or inference mode.\n",
      " |          mask: A mask or list of masks. A mask can be\n",
      " |              either a tensor or None (no mask).\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor if there is a single output, or\n",
      " |          a list of tensors if there are more than one outputs.\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  pop(self)\n",
      " |      Removes the last layer in the model.\n",
      " |      \n",
      " |      Raises:\n",
      " |          TypeError: if there are no layers in the model.\n",
      " |  \n",
      " |  predict_classes(self, x, batch_size=32, verbose=0)\n",
      " |      Generate class predictions for the input samples.\n",
      " |      \n",
      " |      The input samples are processed batch by batch.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: input data, as a Numpy array or list of Numpy arrays\n",
      " |              (if the model has multiple inputs).\n",
      " |          batch_size: integer.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A numpy array of class predictions.\n",
      " |  \n",
      " |  predict_proba(self, x, batch_size=32, verbose=0)\n",
      " |      Generates class probability predictions for the input samples.\n",
      " |      \n",
      " |      The input samples are processed batch by batch.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: input data, as a Numpy array or list of Numpy arrays\n",
      " |              (if the model has multiple inputs).\n",
      " |          batch_size: integer.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A Numpy array of probability predictions.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_config(config, custom_objects=None) from builtins.type\n",
      " |      Instantiates a Model from its config (output of `get_config()`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: Model config dictionary.\n",
      " |          custom_objects: Optional dictionary mapping names\n",
      " |              (strings) to custom classes or functions to be\n",
      " |              considered during deserialization.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A model instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of improperly formatted config dict.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  dynamic\n",
      " |  \n",
      " |  input_spec\n",
      " |      Gets the network's input specs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of `InputSpec` instances (one per input to the model)\n",
      " |              or a single instance if the model has only one input.\n",
      " |  \n",
      " |  layers\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  compile(self, optimizer='rmsprop', loss=None, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None, distribute=None, **kwargs)\n",
      " |      Configures the model for training.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          optimizer: String (name of optimizer) or optimizer instance.\n",
      " |              See `tf.keras.optimizers`.\n",
      " |          loss: String (name of objective function), objective function or\n",
      " |              `tf.losses.Loss` instance. See `tf.losses`. If the model has\n",
      " |              multiple outputs, you can use a different loss on each output by\n",
      " |              passing a dictionary or a list of losses. The loss value that will\n",
      " |              be minimized by the model will then be the sum of all individual\n",
      " |              losses.\n",
      " |          metrics: List of metrics to be evaluated by the model during training\n",
      " |              and testing. Typically you will use `metrics=['accuracy']`.\n",
      " |              To specify different metrics for different outputs of a\n",
      " |              multi-output model, you could also pass a dictionary, such as\n",
      " |              `metrics={'output_a': 'accuracy', 'output_b': ['accuracy', 'mse']}`.\n",
      " |              You can also pass a list (len = len(outputs)) of lists of metrics\n",
      " |              such as `metrics=[['accuracy'], ['accuracy', 'mse']]` or\n",
      " |              `metrics=['accuracy', ['accuracy', 'mse']]`.\n",
      " |          loss_weights: Optional list or dictionary specifying scalar\n",
      " |              coefficients (Python floats) to weight the loss contributions\n",
      " |              of different model outputs.\n",
      " |              The loss value that will be minimized by the model\n",
      " |              will then be the *weighted sum* of all individual losses,\n",
      " |              weighted by the `loss_weights` coefficients.\n",
      " |              If a list, it is expected to have a 1:1 mapping\n",
      " |              to the model's outputs. If a tensor, it is expected to map\n",
      " |              output names (strings) to scalar coefficients.\n",
      " |          sample_weight_mode: If you need to do timestep-wise\n",
      " |              sample weighting (2D weights), set this to `\"temporal\"`.\n",
      " |              `None` defaults to sample-wise weights (1D).\n",
      " |              If the model has multiple outputs, you can use a different\n",
      " |              `sample_weight_mode` on each output by passing a\n",
      " |              dictionary or a list of modes.\n",
      " |          weighted_metrics: List of metrics to be evaluated and weighted\n",
      " |              by sample_weight or class_weight during training and testing.\n",
      " |          target_tensors: By default, Keras will create placeholders for the\n",
      " |              model's target, which will be fed with the target data during\n",
      " |              training. If instead you would like to use your own\n",
      " |              target tensors (in turn, Keras will not expect external\n",
      " |              Numpy data for these targets at training time), you\n",
      " |              can specify them via the `target_tensors` argument. It can be\n",
      " |              a single tensor (for a single-output model), a list of tensors,\n",
      " |              or a dict mapping output names to target tensors.\n",
      " |          distribute: NOT SUPPORTED IN TF 2.0, please create and compile the\n",
      " |              model under distribution strategy scope instead of passing it to\n",
      " |              compile.\n",
      " |          **kwargs: Any additional arguments.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid arguments for\n",
      " |              `optimizer`, `loss`, `metrics` or `sample_weight_mode`.\n",
      " |  \n",
      " |  evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Returns the loss value & metrics values for the model in test mode.\n",
      " |      \n",
      " |      Computation is done in batches.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset.\n",
      " |            - A generator or `keras.utils.Sequence` instance.\n",
      " |          y: Target data. Like the input data `x`,\n",
      " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      " |            tensor targets, or inversely).\n",
      " |            If `x` is a dataset, generator or\n",
      " |            `keras.utils.Sequence` instance, `y` should not be specified (since\n",
      " |            targets will be obtained from the iterator/dataset).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` is your data is in the\n",
      " |              form of symbolic tensors, dataset,\n",
      " |              generators, or `keras.utils.Sequence` instances (since they generate\n",
      " |              batches).\n",
      " |          verbose: 0 or 1. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the test samples, used for weighting the loss function.\n",
      " |              You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              `sample_weight_mode=\"temporal\"` in `compile()`. This argument is not\n",
      " |              supported when `x` is a dataset, instead pass\n",
      " |              sample weights as the third element of `x`.\n",
      " |          steps: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring the evaluation round finished.\n",
      " |              Ignored with the default value of `None`.\n",
      " |              If x is a `tf.data` dataset and `steps` is\n",
      " |              None, 'evaluate' will run until the dataset is exhausted.\n",
      " |              This argument is not supported with array inputs.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during evaluation.\n",
      " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up when using\n",
      " |              process-based threading. If unspecified, `workers` will default\n",
      " |              to 1. If 0, will execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: in case of invalid arguments.\n",
      " |  \n",
      " |  evaluate_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Evaluates the model on a data generator.\n",
      " |      \n",
      " |      The generator should return the same kind of data\n",
      " |      as accepted by `test_on_batch`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          generator: Generator yielding tuples (inputs, targets)\n",
      " |              or (inputs, targets, sample_weights)\n",
      " |              or an instance of `keras.utils.Sequence`\n",
      " |              object in order to avoid duplicate data\n",
      " |              when using multiprocessing.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              to yield from `generator` before stopping.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(generator)` as a number of steps.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during evaluation.\n",
      " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: maximum size for the generator queue\n",
      " |          workers: Integer. Maximum number of processes to spin up\n",
      " |              when using process-based threading.\n",
      " |              If unspecified, `workers` will default to 1. If 0, will\n",
      " |              execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean.\n",
      " |              If `True`, use process-based threading.\n",
      " |              If unspecified, `use_multiprocessing` will default to `False`.\n",
      " |              Note that because this implementation relies on multiprocessing,\n",
      " |              you should not pass non-picklable arguments to the generator\n",
      " |              as they can't be passed easily to children processes.\n",
      " |          verbose: Verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: in case of invalid arguments.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case the generator yields data in an invalid format.\n",
      " |  \n",
      " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False, **kwargs)\n",
      " |      Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset. Should return a tuple\n",
      " |              of either `(inputs, targets)` or\n",
      " |              `(inputs, targets, sample_weights)`.\n",
      " |            - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      " |              or `(inputs, targets, sample weights)`.\n",
      " |          y: Target data. Like the input data `x`,\n",
      " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      " |            tensor targets, or inversely). If `x` is a dataset, generator,\n",
      " |            or `keras.utils.Sequence` instance, `y` should\n",
      " |            not be specified (since targets will be obtained from `x`).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` if your data is in the\n",
      " |              form of symbolic tensors, datasets,\n",
      " |              generators, or `keras.utils.Sequence` instances (since they generate\n",
      " |              batches).\n",
      " |          epochs: Integer. Number of epochs to train the model.\n",
      " |              An epoch is an iteration over the entire `x` and `y`\n",
      " |              data provided.\n",
      " |              Note that in conjunction with `initial_epoch`,\n",
      " |              `epochs` is to be understood as \"final epoch\".\n",
      " |              The model is not trained for a number of iterations\n",
      " |              given by `epochs`, but merely until the epoch\n",
      " |              of index `epochs` is reached.\n",
      " |          verbose: 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |              Note that the progress bar is not particularly useful when\n",
      " |              logged to a file, so verbose=2 is recommended when not running\n",
      " |              interactively (eg, in a production environment).\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See `tf.keras.callbacks`.\n",
      " |          validation_split: Float between 0 and 1.\n",
      " |              Fraction of the training data to be used as validation data.\n",
      " |              The model will set apart this fraction of the training data,\n",
      " |              will not train on it, and will evaluate\n",
      " |              the loss and any model metrics\n",
      " |              on this data at the end of each epoch.\n",
      " |              The validation data is selected from the last samples\n",
      " |              in the `x` and `y` data provided, before shuffling. This argument is\n",
      " |              not supported when `x` is a dataset, generator or\n",
      " |             `keras.utils.Sequence` instance.\n",
      " |          validation_data: Data on which to evaluate\n",
      " |              the loss and any model metrics at the end of each epoch.\n",
      " |              The model will not be trained on this data.\n",
      " |              `validation_data` will override `validation_split`.\n",
      " |              `validation_data` could be:\n",
      " |                - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
      " |                - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
      " |                - dataset\n",
      " |              For the first two cases, `batch_size` must be provided.\n",
      " |              For the last case, `validation_steps` must be provided.\n",
      " |          shuffle: Boolean (whether to shuffle the training data\n",
      " |              before each epoch) or str (for 'batch').\n",
      " |              'batch' is a special option for dealing with the\n",
      " |              limitations of HDF5 data; it shuffles in batch-sized chunks.\n",
      " |              Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only).\n",
      " |              This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples from\n",
      " |              an under-represented class.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the training samples, used for weighting the loss function\n",
      " |              (during training only). You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              `sample_weight_mode=\"temporal\"` in `compile()`. This argument is not\n",
      " |              supported when `x` is a dataset, generator, or\n",
      " |             `keras.utils.Sequence` instance, instead provide the sample_weights\n",
      " |              as the third element of `x`.\n",
      " |          initial_epoch: Integer.\n",
      " |              Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |          steps_per_epoch: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring one epoch finished and starting the\n",
      " |              next epoch. When training with input tensors such as\n",
      " |              TensorFlow data tensors, the default `None` is equal to\n",
      " |              the number of samples in your dataset divided by\n",
      " |              the batch size, or 1 if that cannot be determined. If x is a\n",
      " |              `tf.data` dataset, and 'steps_per_epoch'\n",
      " |              is None, the epoch will run until the input dataset is exhausted.\n",
      " |              This argument is not supported with array inputs.\n",
      " |          validation_steps: Only relevant if `validation_data` is provided and\n",
      " |              is a `tf.data` dataset. Total number of steps (batches of\n",
      " |              samples) to draw before stopping when performing validation\n",
      " |              at the end of every epoch. If validation_data is a `tf.data` dataset\n",
      " |              and 'validation_steps' is None, validation\n",
      " |              will run until the `validation_data` dataset is exhausted.\n",
      " |          validation_freq: Only relevant if validation data is provided. Integer\n",
      " |              or `collections_abc.Container` instance (e.g. list, tuple, etc.).\n",
      " |              If an integer, specifies how many training epochs to run before a\n",
      " |              new validation run is performed, e.g. `validation_freq=2` runs\n",
      " |              validation every 2 epochs. If a Container, specifies the epochs on\n",
      " |              which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
      " |              validation at the end of the 1st, 2nd, and 10th epochs.\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up\n",
      " |              when using process-based threading. If unspecified, `workers`\n",
      " |              will default to 1. If 0, will execute the generator on the main\n",
      " |              thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |          **kwargs: Used for backwards compatibility.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `History` object. Its `History.history` attribute is\n",
      " |          a record of training loss values and metrics values\n",
      " |          at successive epochs, as well as validation loss values\n",
      " |          and validation metrics values (if applicable).\n",
      " |      \n",
      " |      Raises:\n",
      " |          RuntimeError: If the model was never compiled.\n",
      " |          ValueError: In case of mismatch between the provided input data\n",
      " |              and what the model expects.\n",
      " |  \n",
      " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, validation_freq=1, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
      " |      Fits the model on data yielded batch-by-batch by a Python generator.\n",
      " |      \n",
      " |      The generator is run in parallel to the model, for efficiency.\n",
      " |      For instance, this allows you to do real-time data augmentation\n",
      " |      on images on CPU in parallel to training your model on GPU.\n",
      " |      \n",
      " |      The use of `keras.utils.Sequence` guarantees the ordering\n",
      " |      and guarantees the single use of every input per epoch when\n",
      " |      using `use_multiprocessing=True`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          generator: A generator or an instance of `Sequence`\n",
      " |            (`keras.utils.Sequence`)\n",
      " |              object in order to avoid duplicate data\n",
      " |              when using multiprocessing.\n",
      " |              The output of the generator must be either\n",
      " |              - a tuple `(inputs, targets)`\n",
      " |              - a tuple `(inputs, targets, sample_weights)`.\n",
      " |              This tuple (a single output of the generator) makes a single batch.\n",
      " |              Therefore, all arrays in this tuple must have the same length (equal\n",
      " |              to the size of this batch). Different batches may have different\n",
      " |                sizes.\n",
      " |              For example, the last batch of the epoch is commonly smaller than\n",
      " |                the\n",
      " |              others, if the size of the dataset is not divisible by the batch\n",
      " |                size.\n",
      " |              The generator is expected to loop over its data\n",
      " |              indefinitely. An epoch finishes when `steps_per_epoch`\n",
      " |              batches have been seen by the model.\n",
      " |          steps_per_epoch: Total number of steps (batches of samples)\n",
      " |              to yield from `generator` before declaring one epoch\n",
      " |              finished and starting the next epoch. It should typically\n",
      " |              be equal to the number of samples of your dataset\n",
      " |              divided by the batch size.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(generator)` as a number of steps.\n",
      " |          epochs: Integer, total number of iterations on the data.\n",
      " |          verbose: Verbosity mode, 0, 1, or 2.\n",
      " |          callbacks: List of callbacks to be called during training.\n",
      " |          validation_data: This can be either\n",
      " |              - a generator for the validation data\n",
      " |              - a tuple (inputs, targets)\n",
      " |              - a tuple (inputs, targets, sample_weights).\n",
      " |          validation_steps: Only relevant if `validation_data`\n",
      " |              is a generator. Total number of steps (batches of samples)\n",
      " |              to yield from `generator` before stopping.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(validation_data)` as a number of steps.\n",
      " |          validation_freq: Only relevant if validation data is provided. Integer\n",
      " |              or `collections_abc.Container` instance (e.g. list, tuple, etc.).\n",
      " |              If an integer, specifies how many training epochs to run before a\n",
      " |              new validation run is performed, e.g. `validation_freq=2` runs\n",
      " |              validation every 2 epochs. If a Container, specifies the epochs on\n",
      " |              which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
      " |              validation at the end of the 1st, 2nd, and 10th epochs.\n",
      " |          class_weight: Dictionary mapping class indices to a weight\n",
      " |              for the class.\n",
      " |          max_queue_size: Integer. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Maximum number of processes to spin up\n",
      " |              when using process-based threading.\n",
      " |              If unspecified, `workers` will default to 1. If 0, will\n",
      " |              execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean.\n",
      " |              If `True`, use process-based threading.\n",
      " |              If unspecified, `use_multiprocessing` will default to `False`.\n",
      " |              Note that because this implementation relies on multiprocessing,\n",
      " |              you should not pass non-picklable arguments to the generator\n",
      " |              as they can't be passed easily to children processes.\n",
      " |          shuffle: Boolean. Whether to shuffle the order of the batches at\n",
      " |              the beginning of each epoch. Only used with instances\n",
      " |              of `Sequence` (`keras.utils.Sequence`).\n",
      " |              Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          initial_epoch: Epoch at which to start training\n",
      " |              (useful for resuming a previous training run)\n",
      " |      \n",
      " |      Returns:\n",
      " |          A `History` object.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |          def generate_arrays_from_file(path):\n",
      " |              while 1:\n",
      " |                  f = open(path)\n",
      " |                  for line in f:\n",
      " |                      # create numpy arrays of input data\n",
      " |                      # and labels, from each line in the file\n",
      " |                      x1, x2, y = process_line(line)\n",
      " |                      yield ({'input_1': x1, 'input_2': x2}, {'output': y})\n",
      " |                  f.close()\n",
      " |      \n",
      " |          model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n",
      " |                              steps_per_epoch=10000, epochs=10)\n",
      " |      ```\n",
      " |      Raises:\n",
      " |          ValueError: In case the generator yields data in an invalid format.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Retrieves the weights of the model.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A flat list of Numpy arrays.\n",
      " |  \n",
      " |  load_weights(self, filepath, by_name=False)\n",
      " |      Loads all layer weights, either from a TensorFlow or an HDF5 file.\n",
      " |  \n",
      " |  predict(self, x, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Generates output predictions for the input samples.\n",
      " |      \n",
      " |      Computation is done in batches.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input samples. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A `tf.data` dataset.\n",
      " |            - A generator or `keras.utils.Sequence` instance.\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, `batch_size` will default to 32.\n",
      " |              Do not specify the `batch_size` is your data is in the\n",
      " |              form of symbolic tensors, dataset,\n",
      " |              generators, or `keras.utils.Sequence` instances (since they generate\n",
      " |              batches).\n",
      " |          verbose: Verbosity mode, 0 or 1.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              before declaring the prediction round finished.\n",
      " |              Ignored with the default value of `None`. If x is a `tf.data`\n",
      " |              dataset and `steps` is None, `predict` will\n",
      " |              run until the input dataset is exhausted.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during prediction.\n",
      " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      " |              input only. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      " |              only. Maximum number of processes to spin up when using\n",
      " |              process-based threading. If unspecified, `workers` will default\n",
      " |              to 1. If 0, will execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean. Used for generator or\n",
      " |              `keras.utils.Sequence` input only. If `True`, use process-based\n",
      " |              threading. If unspecified, `use_multiprocessing` will default to\n",
      " |              `False`. Note that because this implementation relies on\n",
      " |              multiprocessing, you should not pass non-picklable arguments to\n",
      " |              the generator as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of mismatch between the provided\n",
      " |              input data and the model's expectations,\n",
      " |              or in case a stateful model receives a number of samples\n",
      " |              that is not a multiple of the batch size.\n",
      " |  \n",
      " |  predict_generator(self, generator, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Generates predictions for the input samples from a data generator.\n",
      " |      \n",
      " |      The generator should return the same kind of data as accepted by\n",
      " |      `predict_on_batch`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          generator: Generator yielding batches of input samples\n",
      " |              or an instance of `keras.utils.Sequence` object in order to\n",
      " |              avoid duplicate data when using multiprocessing.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              to yield from `generator` before stopping.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(generator)` as a number of steps.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during prediction.\n",
      " |              See [callbacks](/api_docs/python/tf/keras/callbacks).\n",
      " |          max_queue_size: Maximum size for the generator queue.\n",
      " |          workers: Integer. Maximum number of processes to spin up\n",
      " |              when using process-based threading.\n",
      " |              If unspecified, `workers` will default to 1. If 0, will\n",
      " |              execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean.\n",
      " |              If `True`, use process-based threading.\n",
      " |              If unspecified, `use_multiprocessing` will default to `False`.\n",
      " |              Note that because this implementation relies on multiprocessing,\n",
      " |              you should not pass non-picklable arguments to the generator\n",
      " |              as they can't be passed easily to children processes.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case the generator yields data in an invalid format.\n",
      " |  \n",
      " |  predict_on_batch(self, x)\n",
      " |      Returns predictions for a single batch of samples.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A `tf.data` dataset.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Numpy array(s) of predictions.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of mismatch between given number of inputs and\n",
      " |            expectations of the model.\n",
      " |  \n",
      " |  reset_metrics(self)\n",
      " |      Resets the state of metrics.\n",
      " |  \n",
      " |  test_on_batch(self, x, y=None, sample_weight=None, reset_metrics=True)\n",
      " |      Test the model on a single batch of samples.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |              (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |              if the model has named inputs.\n",
      " |            - A `tf.data` dataset.\n",
      " |          y: Target data. Like the input data `x`,\n",
      " |            it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      " |            It should be consistent with `x` (you cannot have Numpy inputs and\n",
      " |            tensor targets, or inversely). If `x` is a dataset `y` should\n",
      " |            not be specified (since targets will be obtained from the iterator).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |              weights to apply to the model's loss for each sample.\n",
      " |              In the case of temporal data, you can pass a 2D array\n",
      " |              with shape (samples, sequence_length),\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              sample_weight_mode=\"temporal\" in compile(). This argument is not\n",
      " |              supported when `x` is a dataset.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated across\n",
      " |            batches.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar test loss (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid user-provided arguments.\n",
      " |  \n",
      " |  train_on_batch(self, x, y=None, sample_weight=None, class_weight=None, reset_metrics=True)\n",
      " |      Runs a single gradient update on a single batch of data.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          x: Input data. It could be:\n",
      " |            - A Numpy array (or array-like), or a list of arrays\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A TensorFlow tensor, or a list of tensors\n",
      " |                (in case the model has multiple inputs).\n",
      " |            - A dict mapping input names to the corresponding array/tensors,\n",
      " |                if the model has named inputs.\n",
      " |            - A `tf.data` dataset.\n",
      " |          y: Target data. Like the input data `x`, it could be either Numpy\n",
      " |            array(s) or TensorFlow tensor(s). It should be consistent with `x`\n",
      " |            (you cannot have Numpy inputs and tensor targets, or inversely). If\n",
      " |            `x` is a dataset, `y` should not be specified\n",
      " |            (since targets will be obtained from the iterator).\n",
      " |          sample_weight: Optional array of the same length as x, containing\n",
      " |            weights to apply to the model's loss for each sample. In the case of\n",
      " |            temporal data, you can pass a 2D array with shape (samples,\n",
      " |            sequence_length), to apply a different weight to every timestep of\n",
      " |            every sample. In this case you should make sure to specify\n",
      " |            sample_weight_mode=\"temporal\" in compile(). This argument is not\n",
      " |            supported when `x` is a dataset.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers) to a\n",
      " |            weight (float) to apply to the model's loss for the samples from this\n",
      " |            class during training. This can be useful to tell the model to \"pay\n",
      " |            more attention\" to samples from an under-represented class.\n",
      " |          reset_metrics: If `True`, the metrics returned will be only for this\n",
      " |            batch. If `False`, the metrics will be statefully accumulated across\n",
      " |            batches.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Scalar training loss\n",
      " |          (if the model has a single output and no metrics)\n",
      " |          or list of scalars (if the model has multiple outputs\n",
      " |          and/or metrics). The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: In case of invalid user-provided arguments.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.training.Model:\n",
      " |  \n",
      " |  metrics\n",
      " |      Returns the model's metrics added using `compile`, `add_metric` APIs.\n",
      " |  \n",
      " |  metrics_names\n",
      " |      Returns the model's display labels for all outputs.\n",
      " |  \n",
      " |  run_eagerly\n",
      " |      Settable attribute indicating whether the model should run eagerly.\n",
      " |      \n",
      " |      Running eagerly means that your model will be run step by step,\n",
      " |      like Python code. Your model might run slower, but it should become easier\n",
      " |      for you to debug it by stepping into individual layer calls.\n",
      " |      \n",
      " |      By default, we will attempt to compile your model to a static graph to\n",
      " |      deliver the best execution performance.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Boolean, whether the model should run eagerly.\n",
      " |  \n",
      " |  sample_weights\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.network.Network:\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  get_layer(self, name=None, index=None)\n",
      " |      Retrieves a layer based on either its name (unique) or index.\n",
      " |      \n",
      " |      If `name` and `index` are both provided, `index` will take precedence.\n",
      " |      Indices are based on order of horizontal graph traversal (bottom-up).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          name: String, name of layer.\n",
      " |          index: Integer, index of layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: In case of invalid layer name or index.\n",
      " |  \n",
      " |  reset_states(self)\n",
      " |  \n",
      " |  save(self, filepath, overwrite=True, include_optimizer=True, save_format=None, signatures=None, options=None)\n",
      " |      Saves the model to Tensorflow SavedModel or a single HDF5 file.\n",
      " |      \n",
      " |      The savefile includes:\n",
      " |          - The model architecture, allowing to re-instantiate the model.\n",
      " |          - The model weights.\n",
      " |          - The state of the optimizer, allowing to resume training\n",
      " |              exactly where you left off.\n",
      " |      \n",
      " |      This allows you to save the entirety of the state of a model\n",
      " |      in a single file.\n",
      " |      \n",
      " |      Saved models can be reinstantiated via `keras.models.load_model`.\n",
      " |      The model returned by `load_model`\n",
      " |      is a compiled model ready to be used (unless the saved model\n",
      " |      was never compiled in the first place).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String, path to SavedModel or H5 file to save the model.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          include_optimizer: If True, save optimizer's state together.\n",
      " |          save_format: Either 'tf' or 'h5', indicating whether to save the model\n",
      " |            to Tensorflow SavedModel or HDF5. The default is currently 'h5', but\n",
      " |            will switch to 'tf' in TensorFlow 2.0. The 'tf' option is currently\n",
      " |            disabled (use `tf.keras.experimental.export_saved_model` instead).\n",
      " |        signatures: Signatures to save with the SavedModel. Applicable to the 'tf'\n",
      " |          format only. Please see the `signatures` argument in\n",
      " |          `tf.saved_model.save` for details.\n",
      " |        options: Optional `tf.saved_model.SaveOptions` object that specifies\n",
      " |          options for saving to SavedModel.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      from keras.models import load_model\n",
      " |      \n",
      " |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
      " |      del model  # deletes the existing model\n",
      " |      \n",
      " |      # returns a compiled model\n",
      " |      # identical to the previous one\n",
      " |      model = load_model('my_model.h5')\n",
      " |      ```\n",
      " |  \n",
      " |  save_weights(self, filepath, overwrite=True, save_format=None)\n",
      " |      Saves all layer weights.\n",
      " |      \n",
      " |      Either saves in HDF5 or in TensorFlow format based on the `save_format`\n",
      " |      argument.\n",
      " |      \n",
      " |      When saving in HDF5 format, the weight file has:\n",
      " |        - `layer_names` (attribute), a list of strings\n",
      " |            (ordered names of model layers).\n",
      " |        - For every layer, a `group` named `layer.name`\n",
      " |            - For every such layer group, a group attribute `weight_names`,\n",
      " |                a list of strings\n",
      " |                (ordered names of weights tensor of the layer).\n",
      " |            - For every weight in the layer, a dataset\n",
      " |                storing the weight value, named after the weight tensor.\n",
      " |      \n",
      " |      When saving in TensorFlow format, all objects referenced by the network are\n",
      " |      saved in the same format as `tf.train.Checkpoint`, including any `Layer`\n",
      " |      instances or `Optimizer` instances assigned to object attributes. For\n",
      " |      networks constructed from inputs and outputs using `tf.keras.Model(inputs,\n",
      " |      outputs)`, `Layer` instances used by the network are tracked/saved\n",
      " |      automatically. For user-defined classes which inherit from `tf.keras.Model`,\n",
      " |      `Layer` instances must be assigned to object attributes, typically in the\n",
      " |      constructor. See the documentation of `tf.train.Checkpoint` and\n",
      " |      `tf.keras.Model` for details.\n",
      " |      \n",
      " |      While the formats are the same, do not mix `save_weights` and\n",
      " |      `tf.train.Checkpoint`. Checkpoints saved by `Model.save_weights` should be\n",
      " |      loaded using `Model.load_weights`. Checkpoints saved using\n",
      " |      `tf.train.Checkpoint.save` should be restored using the corresponding\n",
      " |      `tf.train.Checkpoint.restore`. Prefer `tf.train.Checkpoint` over\n",
      " |      `save_weights` for training checkpoints.\n",
      " |      \n",
      " |      The TensorFlow format matches objects and variables by starting at a root\n",
      " |      object, `self` for `save_weights`, and greedily matching attribute\n",
      " |      names. For `Model.save` this is the `Model`, and for `Checkpoint.save` this\n",
      " |      is the `Checkpoint` even if the `Checkpoint` has a model attached. This\n",
      " |      means saving a `tf.keras.Model` using `save_weights` and loading into a\n",
      " |      `tf.train.Checkpoint` with a `Model` attached (or vice versa) will not match\n",
      " |      the `Model`'s variables. See the [guide to training\n",
      " |      checkpoints](https://www.tensorflow.org/alpha/guide/checkpoints) for details\n",
      " |      on the TensorFlow format.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          filepath: String, path to the file to save the weights to. When saving\n",
      " |              in TensorFlow format, this is the prefix used for checkpoint files\n",
      " |              (multiple files are generated). Note that the '.h5' suffix causes\n",
      " |              weights to be saved in HDF5 format.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          save_format: Either 'tf' or 'h5'. A `filepath` ending in '.h5' or\n",
      " |              '.keras' will default to HDF5 if `save_format` is `None`. Otherwise\n",
      " |              `None` defaults to 'tf'.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: If h5py is not available when attempting to save in HDF5\n",
      " |              format.\n",
      " |          ValueError: For invalid/unknown format arguments.\n",
      " |  \n",
      " |  summary(self, line_length=None, positions=None, print_fn=None)\n",
      " |      Prints a string summary of the network.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          line_length: Total length of printed lines\n",
      " |              (e.g. set this to adapt the display to different\n",
      " |              terminal window sizes).\n",
      " |          positions: Relative or absolute positions of log elements\n",
      " |              in each line. If not provided,\n",
      " |              defaults to `[.33, .55, .67, 1.]`.\n",
      " |          print_fn: Print function to use. Defaults to `print`.\n",
      " |              It will be called on each line of the summary.\n",
      " |              You can set it to a custom function\n",
      " |              in order to capture the string summary.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if `summary()` is called before the model is built.\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a JSON save file, use\n",
      " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `json.dumps()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A JSON string.\n",
      " |  \n",
      " |  to_yaml(self, **kwargs)\n",
      " |      Returns a yaml string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a yaml save file, use\n",
      " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
      " |      \n",
      " |      `custom_objects` should be a dictionary mapping\n",
      " |      the names of custom losses / layers / etc to the corresponding\n",
      " |      functions / classes.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `yaml.dump()`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A YAML string.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ImportError: if yaml module is not found.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.network.Network:\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  state_updates\n",
      " |      Returns the `updates` from all layers that are stateful.\n",
      " |      \n",
      " |      This is useful for separating training updates and\n",
      " |      state updates, e.g. when we need to update a layer's internal state\n",
      " |      during prediction.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of update ops.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(inputs, self):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)), inputs=True)\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Actvity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(x.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      The `get_losses_for` method allows to retrieve the losses relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        inputs: Ignored when executing eagerly. If anything other than None is\n",
      " |          passed, it signals the losses are conditional on some of the layer's\n",
      " |          inputs, and thus they should only be run where these inputs are\n",
      " |          available. This is the case for activity regularization losses, for\n",
      " |          instance. If `None` is passed, the losses are assumed\n",
      " |          to be unconditional, and will apply across all dataflows of the layer\n",
      " |          (e.g. weight regularization losses).\n",
      " |  \n",
      " |  add_metric(self, value, aggregation=None, name=None)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        aggregation: Sample-wise metric reduction function. If `aggregation=None`,\n",
      " |          it indicates that the metric tensor provided has been aggregated\n",
      " |          already. eg, `bin_acc = BinaryAccuracy(name='acc')` followed by\n",
      " |          `model.add_metric(bin_acc(y_true, y_pred))`. If aggregation='mean', the\n",
      " |          given metric tensor will be sample-wise reduced using `mean` function.\n",
      " |          eg, `model.add_metric(tf.reduce_sum(outputs), name='output_mean',\n",
      " |          aggregation='mean')`.\n",
      " |        name: String metric name.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `aggregation` is anything other than None or `mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs. (deprecated arguments)\n",
      " |      \n",
      " |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(inputs)`. They will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      `inputs` is now automatically inferred\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      The `get_updates_for` method allows to retrieve the updates relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.add_weight` method instead.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter` and\n",
      " |          `collections`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The created variable. Usually either a `Variable` or `ResourceVariable`\n",
      " |        instance. If `partitioner` is not `None`, a `PartitionedVariable`\n",
      " |        instance is returned.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called with partitioned variable regularization and\n",
      " |          eager execution is enabled.\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.__call__` method instead.\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  losses\n",
      " |      Losses which are associated with this `Layer`.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  name\n",
      " |      Returns the name of this module as passed or determined in the ctor.\n",
      " |      \n",
      " |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      " |      parent module names.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of variables owned by this module and it's submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      ```\n",
      " |      class MyModule(tf.Module):\n",
      " |        @tf.Module.with_name_scope\n",
      " |        def __call__(self, x):\n",
      " |          if not hasattr(self, 'w'):\n",
      " |            self.w = tf.Variable(tf.random.normal([x.shape[1], 64]))\n",
      " |          return tf.matmul(x, self.w)\n",
      " |      ```\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      ```\n",
      " |      mod = MyModule()\n",
      " |      mod(tf.ones([8, 32]))\n",
      " |      # ==> <tf.Tensor: ...>\n",
      " |      mod.w\n",
      " |      # ==> <tf.Variable ...'my_module/w:0'>\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      ```\n",
      " |      a = tf.Module()\n",
      " |      b = tf.Module()\n",
      " |      c = tf.Module()\n",
      " |      a.b = b\n",
      " |      b.c = c\n",
      " |      assert list(a.submodules) == [b, c]\n",
      " |      assert list(b.submodules) == [c]\n",
      " |      assert list(c.submodules) == []\n",
      " |      ```\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Dense in module tensorflow.python.keras.layers.core:\n",
      "\n",
      "class Dense(tensorflow.python.keras.engine.base_layer.Layer)\n",
      " |  Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |  \n",
      " |  Just your regular densely-connected NN layer.\n",
      " |  \n",
      " |  `Dense` implements the operation:\n",
      " |  `output = activation(dot(input, kernel) + bias)`\n",
      " |  where `activation` is the element-wise activation function\n",
      " |  passed as the `activation` argument, `kernel` is a weights matrix\n",
      " |  created by the layer, and `bias` is a bias vector created by the layer\n",
      " |  (only applicable if `use_bias` is `True`).\n",
      " |  \n",
      " |  Note: If the input to the layer has a rank greater than 2, then\n",
      " |  it is flattened prior to the initial dot product with `kernel`.\n",
      " |  \n",
      " |  Example:\n",
      " |  \n",
      " |  ```python\n",
      " |  # as first layer in a sequential model:\n",
      " |  model = Sequential()\n",
      " |  model.add(Dense(32, input_shape=(16,)))\n",
      " |  # now the model will take as input arrays of shape (*, 16)\n",
      " |  # and output arrays of shape (*, 32)\n",
      " |  \n",
      " |  # after the first layer, you don't need to specify\n",
      " |  # the size of the input anymore:\n",
      " |  model.add(Dense(32))\n",
      " |  ```\n",
      " |  \n",
      " |  Arguments:\n",
      " |    units: Positive integer, dimensionality of the output space.\n",
      " |    activation: Activation function to use.\n",
      " |      If you don't specify anything, no activation is applied\n",
      " |      (ie. \"linear\" activation: `a(x) = x`).\n",
      " |    use_bias: Boolean, whether the layer uses a bias vector.\n",
      " |    kernel_initializer: Initializer for the `kernel` weights matrix.\n",
      " |    bias_initializer: Initializer for the bias vector.\n",
      " |    kernel_regularizer: Regularizer function applied to\n",
      " |      the `kernel` weights matrix.\n",
      " |    bias_regularizer: Regularizer function applied to the bias vector.\n",
      " |    activity_regularizer: Regularizer function applied to\n",
      " |      the output of the layer (its \"activation\")..\n",
      " |    kernel_constraint: Constraint function applied to\n",
      " |      the `kernel` weights matrix.\n",
      " |    bias_constraint: Constraint function applied to the bias vector.\n",
      " |  \n",
      " |  Input shape:\n",
      " |    N-D tensor with shape: `(batch_size, ..., input_dim)`.\n",
      " |    The most common situation would be\n",
      " |    a 2D input with shape `(batch_size, input_dim)`.\n",
      " |  \n",
      " |  Output shape:\n",
      " |    N-D tensor with shape: `(batch_size, ..., units)`.\n",
      " |    For instance, for a 2D input with shape `(batch_size, input_dim)`,\n",
      " |    the output would have shape `(batch_size, units)`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dense\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (optional, for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(inputs, self):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)), inputs=True)\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Actvity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(x.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      The `get_losses_for` method allows to retrieve the losses relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        inputs: Ignored when executing eagerly. If anything other than None is\n",
      " |          passed, it signals the losses are conditional on some of the layer's\n",
      " |          inputs, and thus they should only be run where these inputs are\n",
      " |          available. This is the case for activity regularization losses, for\n",
      " |          instance. If `None` is passed, the losses are assumed\n",
      " |          to be unconditional, and will apply across all dataflows of the layer\n",
      " |          (e.g. weight regularization losses).\n",
      " |  \n",
      " |  add_metric(self, value, aggregation=None, name=None)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        aggregation: Sample-wise metric reduction function. If `aggregation=None`,\n",
      " |          it indicates that the metric tensor provided has been aggregated\n",
      " |          already. eg, `bin_acc = BinaryAccuracy(name='acc')` followed by\n",
      " |          `model.add_metric(bin_acc(y_true, y_pred))`. If aggregation='mean', the\n",
      " |          given metric tensor will be sample-wise reduced using `mean` function.\n",
      " |          eg, `model.add_metric(tf.reduce_sum(outputs), name='output_mean',\n",
      " |          aggregation='mean')`.\n",
      " |        name: String metric name.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `aggregation` is anything other than None or `mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs. (deprecated arguments)\n",
      " |      \n",
      " |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(inputs)`. They will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      `inputs` is now automatically inferred\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      The `get_updates_for` method allows to retrieve the updates relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.add_weight` method instead.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter` and\n",
      " |          `collections`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The created variable. Usually either a `Variable` or `ResourceVariable`\n",
      " |        instance. If `partitioner` is not `None`, a `PartitionedVariable`\n",
      " |        instance is returned.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called with partitioned variable regularization and\n",
      " |          eager execution is enabled.\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.__call__` method instead.\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  dynamic\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  input_spec\n",
      " |  \n",
      " |  losses\n",
      " |      Losses which are associated with this `Layer`.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |  \n",
      " |  name\n",
      " |      Returns the name of this module as passed or determined in the ctor.\n",
      " |      \n",
      " |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      " |      parent module names.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of variables owned by this module and it's submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      ```\n",
      " |      class MyModule(tf.Module):\n",
      " |        @tf.Module.with_name_scope\n",
      " |        def __call__(self, x):\n",
      " |          if not hasattr(self, 'w'):\n",
      " |            self.w = tf.Variable(tf.random.normal([x.shape[1], 64]))\n",
      " |          return tf.matmul(x, self.w)\n",
      " |      ```\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      ```\n",
      " |      mod = MyModule()\n",
      " |      mod(tf.ones([8, 32]))\n",
      " |      # ==> <tf.Tensor: ...>\n",
      " |      mod.w\n",
      " |      # ==> <tf.Variable ...'my_module/w:0'>\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      ```\n",
      " |      a = tf.Module()\n",
      " |      b = tf.Module()\n",
      " |      c = tf.Module()\n",
      " |      a.b = b\n",
      " |      b.c = c\n",
      " |      assert list(a.submodules) == [b, c]\n",
      " |      assert list(b.submodules) == [c]\n",
      " |      assert list(c.submodules) == []\n",
      " |      ```\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#option 1 of building the sequential model\n",
    "model = Sequential([Dense(4,activation='relu'),\n",
    "                   Dense(2,activation='relu'),\n",
    "                   Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#option 2: more flexible to modify\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='rmsprop',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples\n",
      "Epoch 1/250\n",
      "700/700 [==============================] - 1s 2ms/sample - loss: 256758.0909\n",
      "Epoch 2/250\n",
      "700/700 [==============================] - 0s 89us/sample - loss: 256668.9116\n",
      "Epoch 3/250\n",
      "700/700 [==============================] - 0s 97us/sample - loss: 256589.3255\n",
      "Epoch 4/250\n",
      "700/700 [==============================] - 0s 93us/sample - loss: 256504.7092\n",
      "Epoch 5/250\n",
      "700/700 [==============================] - 0s 89us/sample - loss: 256414.2424\n",
      "Epoch 6/250\n",
      "700/700 [==============================] - 0s 86us/sample - loss: 256314.8452\n",
      "Epoch 7/250\n",
      "700/700 [==============================] - 0s 97us/sample - loss: 256204.5656\n",
      "Epoch 8/250\n",
      "700/700 [==============================] - 0s 94us/sample - loss: 256082.7471\n",
      "Epoch 9/250\n",
      "700/700 [==============================] - 0s 96us/sample - loss: 255947.5175\n",
      "Epoch 10/250\n",
      "700/700 [==============================] - 0s 97us/sample - loss: 255799.5416\n",
      "Epoch 11/250\n",
      "700/700 [==============================] - 0s 106us/sample - loss: 255637.7130\n",
      "Epoch 12/250\n",
      "700/700 [==============================] - 0s 103us/sample - loss: 255462.5273\n",
      "Epoch 13/250\n",
      "700/700 [==============================] - 0s 106us/sample - loss: 255271.5655\n",
      "Epoch 14/250\n",
      "700/700 [==============================] - 0s 100us/sample - loss: 255063.4333\n",
      "Epoch 15/250\n",
      "700/700 [==============================] - 0s 97us/sample - loss: 254838.0836\n",
      "Epoch 16/250\n",
      "700/700 [==============================] - 0s 97us/sample - loss: 254595.1125\n",
      "Epoch 17/250\n",
      "700/700 [==============================] - 0s 86us/sample - loss: 254334.3097\n",
      "Epoch 18/250\n",
      "700/700 [==============================] - 0s 106us/sample - loss: 254051.6484\n",
      "Epoch 19/250\n",
      "700/700 [==============================] - 0s 111us/sample - loss: 253748.0630\n",
      "Epoch 20/250\n",
      "700/700 [==============================] - 0s 139us/sample - loss: 253423.3095\n",
      "Epoch 21/250\n",
      "700/700 [==============================] - 0s 104us/sample - loss: 253074.5434\n",
      "Epoch 22/250\n",
      "700/700 [==============================] - 0s 94us/sample - loss: 252701.5393\n",
      "Epoch 23/250\n",
      "700/700 [==============================] - 0s 93us/sample - loss: 252303.7106\n",
      "Epoch 24/250\n",
      "700/700 [==============================] - 0s 97us/sample - loss: 251880.5697\n",
      "Epoch 25/250\n",
      "700/700 [==============================] - 0s 104us/sample - loss: 251427.4314\n",
      "Epoch 26/250\n",
      "700/700 [==============================] - 0s 93us/sample - loss: 250947.9355\n",
      "Epoch 27/250\n",
      "700/700 [==============================] - 0s 97us/sample - loss: 250439.3047\n",
      "Epoch 28/250\n",
      "700/700 [==============================] - 0s 90us/sample - loss: 249898.7168\n",
      "Epoch 29/250\n",
      "700/700 [==============================] - 0s 107us/sample - loss: 249325.3693\n",
      "Epoch 30/250\n",
      "700/700 [==============================] - 0s 89us/sample - loss: 248720.0199\n",
      "Epoch 31/250\n",
      "700/700 [==============================] - 0s 93us/sample - loss: 248079.3693\n",
      "Epoch 32/250\n",
      "700/700 [==============================] - 0s 117us/sample - loss: 247403.5471\n",
      "Epoch 33/250\n",
      "700/700 [==============================] - 0s 99us/sample - loss: 246692.8332\n",
      "Epoch 34/250\n",
      "700/700 [==============================] - 0s 106us/sample - loss: 245943.5426\n",
      "Epoch 35/250\n",
      "700/700 [==============================] - 0s 99us/sample - loss: 245158.9553\n",
      "Epoch 36/250\n",
      "700/700 [==============================] - 0s 91us/sample - loss: 244329.2437\n",
      "Epoch 37/250\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 243458.9162\n",
      "Epoch 38/250\n",
      "700/700 [==============================] - 0s 101us/sample - loss: 242543.1699\n",
      "Epoch 39/250\n",
      "700/700 [==============================] - 0s 103us/sample - loss: 241590.9570\n",
      "Epoch 40/250\n",
      "700/700 [==============================] - 0s 101us/sample - loss: 240587.5970\n",
      "Epoch 41/250\n",
      "700/700 [==============================] - 0s 113us/sample - loss: 239547.9016\n",
      "Epoch 42/250\n",
      "700/700 [==============================] - 0s 100us/sample - loss: 238456.3012\n",
      "Epoch 43/250\n",
      "700/700 [==============================] - 0s 106us/sample - loss: 237310.5410\n",
      "Epoch 44/250\n",
      "700/700 [==============================] - 0s 96us/sample - loss: 236119.8638\n",
      "Epoch 45/250\n",
      "700/700 [==============================] - 0s 90us/sample - loss: 234877.5790\n",
      "Epoch 46/250\n",
      "700/700 [==============================] - 0s 90us/sample - loss: 233582.1100\n",
      "Epoch 47/250\n",
      "700/700 [==============================] - 0s 91us/sample - loss: 232235.0255\n",
      "Epoch 48/250\n",
      "700/700 [==============================] - 0s 101us/sample - loss: 230841.0654\n",
      "Epoch 49/250\n",
      "700/700 [==============================] - 0s 87us/sample - loss: 229388.6337\n",
      "Epoch 50/250\n",
      "700/700 [==============================] - 0s 106us/sample - loss: 227877.3520\n",
      "Epoch 51/250\n",
      "700/700 [==============================] - 0s 104us/sample - loss: 226303.7352\n",
      "Epoch 52/250\n",
      "700/700 [==============================] - 0s 99us/sample - loss: 224676.2660\n",
      "Epoch 53/250\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 222990.1843\n",
      "Epoch 54/250\n",
      "700/700 [==============================] - 0s 104us/sample - loss: 221239.9179\n",
      "Epoch 55/250\n",
      "700/700 [==============================] - 0s 100us/sample - loss: 219439.5648\n",
      "Epoch 56/250\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 217569.0053\n",
      "Epoch 57/250\n",
      "700/700 [==============================] - 0s 97us/sample - loss: 215631.7127\n",
      "Epoch 58/250\n",
      "700/700 [==============================] - 0s 94us/sample - loss: 213639.9898\n",
      "Epoch 59/250\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 211583.6838\n",
      "Epoch 60/250\n",
      "700/700 [==============================] - 0s 90us/sample - loss: 209457.3414\n",
      "Epoch 61/250\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 207274.9691\n",
      "Epoch 62/250\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 205022.8387\n",
      "Epoch 63/250\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 202693.5124\n",
      "Epoch 64/250\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 200308.4631\n",
      "Epoch 65/250\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 197838.1513\n",
      "Epoch 66/250\n",
      "700/700 [==============================] - 0s 86us/sample - loss: 195325.9045\n",
      "Epoch 67/250\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 192739.9969\n",
      "Epoch 68/250\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 190077.4997\n",
      "Epoch 69/250\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 187344.3067\n",
      "Epoch 70/250\n",
      "700/700 [==============================] - 0s 90us/sample - loss: 184558.1400\n",
      "Epoch 71/250\n",
      "700/700 [==============================] - 0s 89us/sample - loss: 181701.2401\n",
      "Epoch 72/250\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 178773.6849\n",
      "Epoch 73/250\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 175776.5106\n",
      "Epoch 74/250\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 172723.8335\n",
      "Epoch 75/250\n",
      "700/700 [==============================] - 0s 99us/sample - loss: 169597.3034\n",
      "Epoch 76/250\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 166395.8071\n",
      "Epoch 77/250\n",
      "700/700 [==============================] - 0s 94us/sample - loss: 163134.0571\n",
      "Epoch 78/250\n",
      "700/700 [==============================] - 0s 86us/sample - loss: 159819.2296\n",
      "Epoch 79/250\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 156436.6347\n",
      "Epoch 80/250\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 152995.5171\n",
      "Epoch 81/250\n",
      "700/700 [==============================] - 0s 93us/sample - loss: 149500.6376\n",
      "Epoch 82/250\n",
      "700/700 [==============================] - 0s 90us/sample - loss: 145941.4555\n",
      "Epoch 83/250\n",
      "700/700 [==============================] - 0s 96us/sample - loss: 142331.4375\n",
      "Epoch 84/250\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 138654.0016\n",
      "Epoch 85/250\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 134944.2168\n",
      "Epoch 86/250\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 131172.6388\n",
      "Epoch 87/250\n",
      "700/700 [==============================] - 0s 90us/sample - loss: 127380.7192\n",
      "Epoch 88/250\n",
      "700/700 [==============================] - 0s 91us/sample - loss: 123525.6925\n",
      "Epoch 89/250\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 119620.2010\n",
      "Epoch 90/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 93us/sample - loss: 115695.7779\n",
      "Epoch 91/250\n",
      "700/700 [==============================] - 0s 91us/sample - loss: 111747.3012\n",
      "Epoch 92/250\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 107755.9057\n",
      "Epoch 93/250\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 103732.3046\n",
      "Epoch 94/250\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 99713.9892\n",
      "Epoch 95/250\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 95646.5837\n",
      "Epoch 96/250\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 91570.0439\n",
      "Epoch 97/250\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 87518.5079\n",
      "Epoch 98/250\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 83438.5344\n",
      "Epoch 99/250\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 79364.5054\n",
      "Epoch 100/250\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 75309.7250\n",
      "Epoch 101/250\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 71285.0873\n",
      "Epoch 102/250\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 67277.4740\n",
      "Epoch 103/250\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 63287.1883\n",
      "Epoch 104/250\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 59347.6617\n",
      "Epoch 105/250\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 55443.6139\n",
      "Epoch 106/250\n",
      "700/700 [==============================] - 0s 91us/sample - loss: 51610.5055\n",
      "Epoch 107/250\n",
      "700/700 [==============================] - 0s 87us/sample - loss: 47849.1778\n",
      "Epoch 108/250\n",
      "700/700 [==============================] - 0s 87us/sample - loss: 44145.4644\n",
      "Epoch 109/250\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 40522.5713\n",
      "Epoch 110/250\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 36998.5372\n",
      "Epoch 111/250\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 33584.9019\n",
      "Epoch 112/250\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 30273.4650\n",
      "Epoch 113/250\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 27092.3152\n",
      "Epoch 114/250\n",
      "700/700 [==============================] - 0s 89us/sample - loss: 24039.5660\n",
      "Epoch 115/250\n",
      "700/700 [==============================] - 0s 100us/sample - loss: 21125.3711\n",
      "Epoch 116/250\n",
      "700/700 [==============================] - 0s 96us/sample - loss: 18357.3238\n",
      "Epoch 117/250\n",
      "700/700 [==============================] - 0s 99us/sample - loss: 15778.0605\n",
      "Epoch 118/250\n",
      "700/700 [==============================] - 0s 186us/sample - loss: 13394.5297\n",
      "Epoch 119/250\n",
      "700/700 [==============================] - 0s 128us/sample - loss: 11220.2043\n",
      "Epoch 120/250\n",
      "700/700 [==============================] - 0s 94us/sample - loss: 9228.8476\n",
      "Epoch 121/250\n",
      "700/700 [==============================] - 0s 114us/sample - loss: 7435.3827\n",
      "Epoch 122/250\n",
      "700/700 [==============================] - 0s 104us/sample - loss: 5925.4308\n",
      "Epoch 123/250\n",
      "700/700 [==============================] - 0s 111us/sample - loss: 4641.4927\n",
      "Epoch 124/250\n",
      "700/700 [==============================] - 0s 87us/sample - loss: 3600.3303\n",
      "Epoch 125/250\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 2847.8832\n",
      "Epoch 126/250\n",
      "700/700 [==============================] - 0s 90us/sample - loss: 2339.7793\n",
      "Epoch 127/250\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 2078.2140\n",
      "Epoch 128/250\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1968.3651\n",
      "Epoch 129/250\n",
      "700/700 [==============================] - 0s 91us/sample - loss: 1933.0113\n",
      "Epoch 130/250\n",
      "700/700 [==============================] - 0s 91us/sample - loss: 1907.4383\n",
      "Epoch 131/250\n",
      "700/700 [==============================] - 0s 93us/sample - loss: 1886.3281\n",
      "Epoch 132/250\n",
      "700/700 [==============================] - 0s 87us/sample - loss: 1861.4901\n",
      "Epoch 133/250\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 1840.4045\n",
      "Epoch 134/250\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1822.0089\n",
      "Epoch 135/250\n",
      "700/700 [==============================] - 0s 93us/sample - loss: 1798.0479\n",
      "Epoch 136/250\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 1780.4555\n",
      "Epoch 137/250\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 1759.5198\n",
      "Epoch 138/250\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1740.1619\n",
      "Epoch 139/250\n",
      "700/700 [==============================] - 0s 86us/sample - loss: 1716.4607\n",
      "Epoch 140/250\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 1695.5180\n",
      "Epoch 141/250\n",
      "700/700 [==============================] - 0s 97us/sample - loss: 1675.5166\n",
      "Epoch 142/250\n",
      "700/700 [==============================] - 0s 94us/sample - loss: 1654.2143\n",
      "Epoch 143/250\n",
      "700/700 [==============================] - 0s 89us/sample - loss: 1633.8004\n",
      "Epoch 144/250\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 1612.2789\n",
      "Epoch 145/250\n",
      "700/700 [==============================] - 0s 94us/sample - loss: 1590.1448\n",
      "Epoch 146/250\n",
      "700/700 [==============================] - 0s 93us/sample - loss: 1569.0010\n",
      "Epoch 147/250\n",
      "700/700 [==============================] - 0s 90us/sample - loss: 1548.0878\n",
      "Epoch 148/250\n",
      "700/700 [==============================] - 0s 90us/sample - loss: 1525.3111\n",
      "Epoch 149/250\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 1504.8735\n",
      "Epoch 150/250\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 1487.2504\n",
      "Epoch 151/250\n",
      "700/700 [==============================] - 0s 87us/sample - loss: 1467.0450\n",
      "Epoch 152/250\n",
      "700/700 [==============================] - 0s 94us/sample - loss: 1446.2221\n",
      "Epoch 153/250\n",
      "700/700 [==============================] - 0s 94us/sample - loss: 1424.0949\n",
      "Epoch 154/250\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 1406.0160\n",
      "Epoch 155/250\n",
      "700/700 [==============================] - 0s 99us/sample - loss: 1387.1953\n",
      "Epoch 156/250\n",
      "700/700 [==============================] - 0s 93us/sample - loss: 1369.2548\n",
      "Epoch 157/250\n",
      "700/700 [==============================] - 0s 91us/sample - loss: 1349.2132\n",
      "Epoch 158/250\n",
      "700/700 [==============================] - 0s 91us/sample - loss: 1333.1233\n",
      "Epoch 159/250\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 1312.7735\n",
      "Epoch 160/250\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 1293.0294\n",
      "Epoch 161/250\n",
      "700/700 [==============================] - 0s 87us/sample - loss: 1276.1317\n",
      "Epoch 162/250\n",
      "700/700 [==============================] - 0s 91us/sample - loss: 1256.6242\n",
      "Epoch 163/250\n",
      "700/700 [==============================] - 0s 90us/sample - loss: 1236.9106\n",
      "Epoch 164/250\n",
      "700/700 [==============================] - 0s 97us/sample - loss: 1217.0055\n",
      "Epoch 165/250\n",
      "700/700 [==============================] - 0s 86us/sample - loss: 1197.4468\n",
      "Epoch 166/250\n",
      "700/700 [==============================] - 0s 98us/sample - loss: 1176.8098\n",
      "Epoch 167/250\n",
      "700/700 [==============================] - 0s 111us/sample - loss: 1158.3134\n",
      "Epoch 168/250\n",
      "700/700 [==============================] - 0s 113us/sample - loss: 1140.4421\n",
      "Epoch 169/250\n",
      "700/700 [==============================] - 0s 107us/sample - loss: 1121.4148\n",
      "Epoch 170/250\n",
      "700/700 [==============================] - 0s 110us/sample - loss: 1103.4038\n",
      "Epoch 171/250\n",
      "700/700 [==============================] - 0s 123us/sample - loss: 1086.0756\n",
      "Epoch 172/250\n",
      "700/700 [==============================] - 0s 113us/sample - loss: 1069.1207\n",
      "Epoch 173/250\n",
      "700/700 [==============================] - 0s 103us/sample - loss: 1051.2957\n",
      "Epoch 174/250\n",
      "700/700 [==============================] - 0s 103us/sample - loss: 1033.4684\n",
      "Epoch 175/250\n",
      "700/700 [==============================] - 0s 106us/sample - loss: 1015.4415\n",
      "Epoch 176/250\n",
      "700/700 [==============================] - 0s 104us/sample - loss: 997.3692\n",
      "Epoch 177/250\n",
      "700/700 [==============================] - 0s 107us/sample - loss: 980.3129\n",
      "Epoch 178/250\n",
      "700/700 [==============================] - 0s 104us/sample - loss: 963.3357\n",
      "Epoch 179/250\n",
      "700/700 [==============================] - 0s 111us/sample - loss: 949.0080\n",
      "Epoch 180/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - ETA: 0s - loss: 948.438 - 0s 113us/sample - loss: 931.8720\n",
      "Epoch 181/250\n",
      "700/700 [==============================] - 0s 110us/sample - loss: 914.8787\n",
      "Epoch 182/250\n",
      "700/700 [==============================] - 0s 97us/sample - loss: 898.1892\n",
      "Epoch 183/250\n",
      "700/700 [==============================] - 0s 91us/sample - loss: 881.3638\n",
      "Epoch 184/250\n",
      "700/700 [==============================] - 0s 90us/sample - loss: 864.1586\n",
      "Epoch 185/250\n",
      "700/700 [==============================] - 0s 91us/sample - loss: 847.2112\n",
      "Epoch 186/250\n",
      "700/700 [==============================] - 0s 90us/sample - loss: 832.2117\n",
      "Epoch 187/250\n",
      "700/700 [==============================] - 0s 91us/sample - loss: 815.4737\n",
      "Epoch 188/250\n",
      "700/700 [==============================] - 0s 95us/sample - loss: 799.6481\n",
      "Epoch 189/250\n",
      "700/700 [==============================] - 0s 91us/sample - loss: 782.3452\n",
      "Epoch 190/250\n",
      "700/700 [==============================] - 0s 97us/sample - loss: 767.5071\n",
      "Epoch 191/250\n",
      "700/700 [==============================] - 0s 106us/sample - loss: 750.8743\n",
      "Epoch 192/250\n",
      "700/700 [==============================] - 0s 95us/sample - loss: 733.9034\n",
      "Epoch 193/250\n",
      "700/700 [==============================] - 0s 96us/sample - loss: 717.6504\n",
      "Epoch 194/250\n",
      "700/700 [==============================] - 0s 97us/sample - loss: 699.9331\n",
      "Epoch 195/250\n",
      "700/700 [==============================] - 0s 96us/sample - loss: 686.1734\n",
      "Epoch 196/250\n",
      "700/700 [==============================] - 0s 92us/sample - loss: 670.7334\n",
      "Epoch 197/250\n",
      "700/700 [==============================] - 0s 90us/sample - loss: 656.9473\n",
      "Epoch 198/250\n",
      "700/700 [==============================] - 0s 89us/sample - loss: 642.1208\n",
      "Epoch 199/250\n",
      "700/700 [==============================] - 0s 84us/sample - loss: 626.3915\n",
      "Epoch 200/250\n",
      "700/700 [==============================] - 0s 97us/sample - loss: 613.4635\n",
      "Epoch 201/250\n",
      "700/700 [==============================] - 0s 80us/sample - loss: 599.1487\n",
      "Epoch 202/250\n",
      "700/700 [==============================] - 0s 93us/sample - loss: 585.0634\n",
      "Epoch 203/250\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 572.1269\n",
      "Epoch 204/250\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 557.2724\n",
      "Epoch 205/250\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 545.4746\n",
      "Epoch 206/250\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 532.4902\n",
      "Epoch 207/250\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 519.1965\n",
      "Epoch 208/250\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 504.5876\n",
      "Epoch 209/250\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 490.9505\n",
      "Epoch 210/250\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 478.6084\n",
      "Epoch 211/250\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 466.3845\n",
      "Epoch 212/250\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 453.2177\n",
      "Epoch 213/250\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 439.9018\n",
      "Epoch 214/250\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 429.1513\n",
      "Epoch 215/250\n",
      "700/700 [==============================] - 0s 81us/sample - loss: 417.4522\n",
      "Epoch 216/250\n",
      "700/700 [==============================] - 0s 104us/sample - loss: 405.8750\n",
      "Epoch 217/250\n",
      "700/700 [==============================] - 0s 83us/sample - loss: 392.2643\n",
      "Epoch 218/250\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 383.0317\n",
      "Epoch 219/250\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 370.6236\n",
      "Epoch 220/250\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 358.6994\n",
      "Epoch 221/250\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 347.2392\n",
      "Epoch 222/250\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 336.4580\n",
      "Epoch 223/250\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 325.3956\n",
      "Epoch 224/250\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 314.8671\n",
      "Epoch 225/250\n",
      "700/700 [==============================] - 0s 89us/sample - loss: 303.6313\n",
      "Epoch 226/250\n",
      "700/700 [==============================] - 0s 73us/sample - loss: 293.2338\n",
      "Epoch 227/250\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 283.5898\n",
      "Epoch 228/250\n",
      "700/700 [==============================] - 0s 67us/sample - loss: 273.2757\n",
      "Epoch 229/250\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 265.1205\n",
      "Epoch 230/250\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 255.3885\n",
      "Epoch 231/250\n",
      "700/700 [==============================] - 0s 74us/sample - loss: 247.0295\n",
      "Epoch 232/250\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 237.0788\n",
      "Epoch 233/250\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 228.2488\n",
      "Epoch 234/250\n",
      "700/700 [==============================] - 0s 66us/sample - loss: 220.5373\n",
      "Epoch 235/250\n",
      "700/700 [==============================] - 0s 64us/sample - loss: 211.8716\n",
      "Epoch 236/250\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 203.6535\n",
      "Epoch 237/250\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 195.3261\n",
      "Epoch 238/250\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 187.5065\n",
      "Epoch 239/250\n",
      "700/700 [==============================] - 0s 86us/sample - loss: 179.4967\n",
      "Epoch 240/250\n",
      "700/700 [==============================] - 0s 69us/sample - loss: 171.8827\n",
      "Epoch 241/250\n",
      "700/700 [==============================] - 0s 70us/sample - loss: 164.1846\n",
      "Epoch 242/250\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 157.8481\n",
      "Epoch 243/250\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 150.8507\n",
      "Epoch 244/250\n",
      "700/700 [==============================] - 0s 79us/sample - loss: 144.5728\n",
      "Epoch 245/250\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 138.3940\n",
      "Epoch 246/250\n",
      "700/700 [==============================] - 0s 71us/sample - loss: 132.0648\n",
      "Epoch 247/250\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 125.8769\n",
      "Epoch 248/250\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 120.1116\n",
      "Epoch 249/250\n",
      "700/700 [==============================] - 0s 76us/sample - loss: 114.3488\n",
      "Epoch 250/250\n",
      "700/700 [==============================] - 0s 77us/sample - loss: 108.0608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x244bbbe8f48>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train,epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x244bd53f048>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
